{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Intelligence\n",
    "## Python crash course\n",
    "## Pandas Library (and Numpy)\n",
    "\n",
    "#### Prof. Claudio Lucchese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy \n",
    "\n",
    "http://www.numpy.org/\n",
    "\n",
    "**NumPy** stands for **Numerical Python**.\n",
    "\n",
    "NumPy is a fundamental package for efficient scientific and numerical computing.\n",
    "\n",
    "It provides:\n",
    "- efficient methods for managing arrays and matrices, and operations on them\n",
    "- several mathematical functions (variance, standard deviation, cumulative sum, ...)\n",
    "- other: fitting a polynomial, finding the minimum of a function, Fast Fourier Transform, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix representation and operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform a nested list into a 2D matrix\n",
    "\n",
    "import numpy as np\n",
    "a = np.array( [ [1.,2.,3.],\n",
    "                [4.,5.,6.] ] )\n",
    "\n",
    "print (\"Matrix a:\")\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise operations\n",
    "b = a + 2\n",
    "print (\"Matrix b=a+2:\")\n",
    "print (b)\n",
    "print()\n",
    "\n",
    "c = a * 7\n",
    "print (\"Matrix c=a*7:\")\n",
    "print (c)\n",
    "print()\n",
    "\n",
    "d = b - a\n",
    "print (\"Matrix d=b-a:\")\n",
    "print (d)\n",
    "print()\n",
    "\n",
    "e = c / a\n",
    "print (\"Matrix e=c/a:\")\n",
    "print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix transpose and multiplication\n",
    "z = np.matmul(a, b.T)\n",
    "print (z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical functions\n",
    "\n",
    "See https://docs.scipy.org/doc/numpy/reference/ufuncs.html for more information.\n",
    "\n",
    "Let's test `sqrt()` (square root) and `maximum()` (element-wise maximum of two arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.array( [ [1.,2.,3.],[4.,5.,6.] ] )\n",
    "b = np.array( [ [3.,3.,7.],[1.,1.,2.] ] )\n",
    "\n",
    "print (\"exp function\")\n",
    "print ( np.exp(a))\n",
    "print ()\n",
    "\n",
    "print (\"element-wise maximum\")\n",
    "print ( np.maximum(a,b) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation and Statistical methods\n",
    "\n",
    "Typical `sum`, `mean`, `var`, are available ...\n",
    "\n",
    "In case of matrices, it is possible to specify the **direction** of the operation.\n",
    " - see https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html#numpy.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array( [ [1.,2.,3.],\n",
    "                [4.,5.,6.] ] )\n",
    "\n",
    "print (m)\n",
    "print ()\n",
    "\n",
    "print (\"No direction/axis\")\n",
    "print ( np.mean(m) )\n",
    "print ()\n",
    "\n",
    "print (\"mean over axis 0 (across rows)\")\n",
    "print ( np.mean(m, axis=0) )\n",
    "print ()\n",
    "\n",
    "print (\"mean over axis 1 (across cols)\")\n",
    "print ( np.mean(m, axis=1) )\n",
    "print ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Views\n",
    "\n",
    "It is possible to access elements of matrices/array in a similar way to Python lists.\n",
    "\n",
    "Slices of a matrix are implemented as **views**, **not copies**, on the original data, sharing the same memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array( [ [1.,2.,3.],\n",
    "                [4.,5.,6.] ] )\n",
    "\n",
    "print (m)\n",
    "print ()\n",
    "\n",
    "print (\"view/indexing\")\n",
    "view = m[:,1]  # allo rows, column with index 1\n",
    "print ( view )\n",
    "print ()\n",
    "\n",
    "print (\"modified view and original data\")\n",
    "view[:] = 33\n",
    "print ( view )\n",
    "print ()\n",
    "print ( m )    # also m is modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Fancy Indexing\n",
    "\n",
    "Similarly to python, the sort method can be used to sort an array or to get a sorted copy.\n",
    "\n",
    "There is no `key` parameter.\n",
    "\n",
    "See https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.sort.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1,-2,3,-4,5])\n",
    "\n",
    "s = np.sort(data)\n",
    "print ( \"sorted copy    \", s )\n",
    "print ( \"original data  \", data)\n",
    "print()\n",
    "\n",
    "data.sort()\n",
    "print ( \"after data.sort()\" )\n",
    "print ( \"original data  \", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also sorting may have a direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array( [ [3., 5.,2.],[6., 1.,5.] ] )\n",
    "\n",
    "print (m)\n",
    "\n",
    "print (\"sort over axis 0 (across rows)\")\n",
    "print ( np.sort(m, axis=0) )\n",
    "print()\n",
    "\n",
    "print (\"sort over axis 1 (across cols)\")\n",
    "print ( np.sort(m, axis=1) )\n",
    "print()\n",
    "\n",
    "print (\"flatten and then sort\")\n",
    "print ( np.sort(m, axis=None) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful method is `argsort`, which returns the positions of the elements in sorted order, withouth modifying the original array.\n",
    "\n",
    "The output of `argsort`, can be used in conjuction with fancy indexing.\n",
    "\n",
    "Example: sort by income and print the corresponding name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array([  'Mark', 'Joe', 'Will', 'Bob', 'Jane', 'Carol', 'Donald'])\n",
    "salaries = np.array([2000,   1200,  3000,  2100,   1580,   1700,    900])\n",
    "\n",
    "sorted_pos = np.argsort(salaries)\n",
    "print (\"sorted positions\", sorted_pos)\n",
    "\n",
    "print ( \"ages\",  names[sorted_pos] ) # This is called fancy indexing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "Find the minimum of a function given it first derivative.\n",
    "\n",
    "See https://docs.scipy.org/doc/scipy/reference/optimize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "def f(x):\n",
    "    return (x**3 - 1)  # only one real root at x = 1\n",
    "\n",
    "def fprime(x):\n",
    "    return 3*x**2\n",
    "\n",
    "sol = optimize.root_scalar( f,                # function\n",
    "                            x0=0.2,           # initial guess\n",
    "                            fprime=fprime,    # first derivative\n",
    "                            method='newton')  # optimization method\n",
    "\n",
    "print (\"The root of the function is:\", sol.root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Numpy ?\n",
    "\n",
    "NumPy deserves your interest, especially for implementing numerical algorithms, matrix-based operations, and to exploit its great algorithms (see also scipy).\n",
    "\n",
    "From a data perspective, it provides a low level access. We will see the Pandas library, which is more data-oriented and it shares several commonalities with NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas: Python Data Analysis Library\n",
    "\n",
    "See: https://pandas.pydata.org/\n",
    "\n",
    "Pandas is an open source providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's read our dataset with one line of code!\n",
    "\n",
    "We can read an excel file!\n",
    "\n",
    "See: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html\n",
    "\n",
    "Check also the `sheet_name` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_file = './datasets/tennis/2019.xlsx'\n",
    "\n",
    "df = pd.read_excel(dataset_file) \n",
    "df.head() # see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(df))\n",
    "# see https://pandas.pydata.org/pandas-docs/stable/reference/frame.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe\n",
    "\n",
    "- **DataFrame** is a 2-dimensional table of data and contains an ordered collection of columns, each of which can be a different value type (numeric, string, boolean, etc.).\n",
    "\n",
    "See: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "\n",
    "**Features of DataFrame:**\n",
    "- Mutable\n",
    "- Potentially columns are of different types\n",
    "- Labeled axes (rows and columns)\n",
    "- Can Perform Arithmetic operations on rows and columns\n",
    "\n",
    "A DataFrame can be seen as a dictionary of columns (indeed, pandas Series), all sharing the same index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask the number of rows and columns.\n",
    "We can access index and columns labels with attributes `index`and `column`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"df.shape:\", df.shape)\n",
    "print(\"df.index:\", df.index)\n",
    "print(\"df.columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What is the number of matches?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_file = './datasets/tennis/2019.xlsx'\n",
    "df = pd.read_excel(dataset_file) \n",
    "\n",
    "print (\"Dataframe shape is:\", df.shape)\n",
    "num_matches, num_columns = df.shape\n",
    "print (\"The number of matches is:\", num_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names\n",
    "\n",
    "Both index and columns have an attribute `name` to specify their names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name   = \"Match ID\"\n",
    "df.columns.name = \"Attributes\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical summary\n",
    "\n",
    "We can get a statistical summary for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "\n",
    "A specific data type is used to store and manage the information in the dataframe. This is important to understand which operations can be performed on the different columns.\n",
    "\n",
    "Note that also the non-null values are reported. It is not uncommon to have missing values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column selection, addition, and deletion\n",
    "\n",
    "See: https://pandas.pydata.org/pandas-docs/stable/indexing.html.\n",
    "\n",
    "Pandas provides several (sometimes confusing) ways to access the columns of a data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example (Selection)\n",
    "We can select a column by specifying its name. \n",
    "\n",
    "This operation gives us Pandas Series.\n",
    "\n",
    "Note that the index is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = df[\"Winner\"] \n",
    "\n",
    "print(\"a:\\n\", a)\n",
    "print(\"Type: \", type(a))\n",
    "print()\n",
    "\n",
    "# Equivalent to\n",
    "\n",
    "a = df.Winner\n",
    "print(\"a:\\n\", a)\n",
    "print(\"Type: \", type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also select multiple columns. In this case you need to use a list.\n",
    "\n",
    "Note that the result is a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = df[ [\"Winner\",\"Loser\"] ] \n",
    "\n",
    "wl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example (Addition)\n",
    "We can add a new column by passing a NumPy array (or a list, Pandas Series, and more) or a single number.\n",
    "\n",
    "In case of a list/array, the length of the array must equal the number of rows (otherwise a ValueError exception is raised)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df.shape:\", df.shape)\n",
    "\n",
    "         # note that len gives us the number of rows\n",
    "df['meaning-less']   = np.ones( len(df) ) \n",
    "df['meaning-less-2'] = 2\n",
    "df['meaning-less-3'] = df['B365W']*2\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example (Deletion)\n",
    "\n",
    "Method `drop()` can be used to remove a column. We need to specify axis=1 (axis=0 are the rows).\n",
    "The built-in `del` can also be used.\n",
    "\n",
    "`inplace` argument (default is False)  is common in several Pandas' functions that modify the DataFrame. \n",
    "If True, it says that the function has to modify the DataFrame itself instead of returning a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        # drop returns a new dataframe\n",
    "df = df.drop('meaning-less', axis=1)   \n",
    "        # unless inplace is set to True\n",
    "df.drop('meaning-less-2', axis=1, inplace=True)\n",
    "        # alternative\n",
    "del df['meaning-less-3']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "Index does not need to be in integer, and it does not need to be unique.\n",
    "We can choose one of the column to be the index with function `set_index()`. \n",
    "\n",
    "Note that the old index is lost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.set_index(\"Location\", inplace=True) # Alternative to df = df.set_index(\"Location\")\n",
    "\n",
    "# Note the new name of the index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: List the tournament names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_file = './datasets/tennis/2019.xlsx'\n",
    "df = pd.read_excel(dataset_file) \n",
    "\n",
    "df['Tournament']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set( df['Tournament'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do this because a pandas Series is iterable, and a python set can be build from any iterable.\n",
    "\n",
    "You can iterate in two ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for v in df['Tournament']:\n",
    "    print (v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to enumerate\n",
    "for index,v in df['Tournament'].iteritems():\n",
    "    print (index, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows to do better then using python sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tournament'].unique()\n",
    "# see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Tournament'].value_counts()\n",
    "# see: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Note it returns a Series\n",
    "for tournament, count in df['Tournament'].value_counts().iteritems():\n",
    "    print (\"During the\",tournament, \"there were\", count, \"matches.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: Find player with most wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_file = './datasets/tennis/2019.xlsx'\n",
    "df = pd.read_excel(dataset_file) \n",
    "\n",
    "winners = df['Winner'].value_counts()\n",
    "most_winner = winners.index[0]\n",
    "most_winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A focus  on Series\n",
    "\n",
    "- **Series** is a one-dimensional array-like object containing a sequence of values (of similar types to NumPy types) and an associated array of data labels, called its *index*.\n",
    "\n",
    "It provides functionalities similar to that of python lists and python dictionaries.\n",
    "\n",
    "As for Dataframes, Series have an index. The default index is made by numbers from 0-1, otherwise we can specify it, and we can use arbitrary labels as index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pds = pd.Series([4, 7, -5, -3])\n",
    "\n",
    "print(pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = pd.Series( [4, 7, -5, -3], \n",
    "                 index=[\"George\", \"John\", \"Paul\", \"Ringo\"])\n",
    "\n",
    "# Series my have a name and its index may also have a name\n",
    "pds.name = \"The Beatles\"\n",
    "pds.index.name = \"Member\"\n",
    "\n",
    "print(pds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing\n",
    "\n",
    "Series indexing works analogously to Python list if you want to access by position, or similar to python dictionaries if you want to access by index value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access by position\n",
    "print (pds[2])\n",
    "print ()\n",
    "\n",
    "# access by index value\n",
    "print (pds['Paul'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fancy indexing by position\n",
    "print (pds[ [0,3] ])\n",
    "print ()\n",
    "\n",
    "# Fancy indexing by index calue\n",
    "p = pds[  ['John', 'Ringo']  ]\n",
    "print ( p )\n",
    "print ()\n",
    "\n",
    "# note: they return pands series\n",
    "print (type(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also have Boolean Indexing\n",
    "print (pds[ [True, False, False, True] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing, loc and iloc\n",
    "\n",
    "Pandas tries to understand whether you are using a position or an index value. (What if they are both integers?)\n",
    "\n",
    "To avoid confusion, one good recommendation is to use `loc` and `iloc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "As in Python, we can use slicing with positions. **Right extreme is NOT included**.\n",
    "\n",
    "Recommendation: use `iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( pds )\n",
    "print ()\n",
    "\n",
    "print ( pds[1:3] )\n",
    "print ()\n",
    "\n",
    "print ( pds.iloc[1:3] )\n",
    "print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "But we can also use slicing with labels. **Right extreme is included**. Index must be sorted !\n",
    "\n",
    "Recommendation: use `loc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( pds['George':'P'] )     # 'P' is not present\n",
    "print ()\n",
    "\n",
    "print ( pds['George':'Paul'] )\n",
    "print ()\n",
    "\n",
    "print ( pds.loc['George':'Paul'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for a dictionary you can check for presence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"'John' in pds:\", \"John\" in pds )\n",
    "print(\"'Mark' in pds:\", \"Mark\" in pds )\n",
    "\n",
    "# try\n",
    "# pds[\"Mark\"] # KeyError exception if not present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series are mutable\n",
    "\n",
    "We can change its values with an assignment (also with slicing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pds)\n",
    "print()\n",
    "\n",
    "pds['Paul'] = 42\n",
    "\n",
    "pds['George':'Paul'] = 5\n",
    "\n",
    "print(pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds['Gennaro'] = 12 # It's a honor be part of this group\n",
    "\n",
    "print(pds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering + Boolean Indexing\n",
    "\n",
    "We can filter entries of a Series.\n",
    "\n",
    "(You have the same in NumPy's Boolean indexing).\n",
    "\n",
    "#### Example\n",
    "Here we get only rows with a positive value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pds > 0\n",
    "print(\"pds > 0\\n\", a)\n",
    "print()\n",
    "\n",
    "print(\"pds[ pds > 0]:\\n\", \n",
    "       pds[ pds > 0 ]  ) # get only positive values of pds \n",
    "print(\"Fab Four are back!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bye-bye gennaro\n",
    "\n",
    "psd = pds.drop('Gennaro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "We can perform NumPy operations on a Series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"pds*2:\\n\", pds*2 )\n",
    "print()\n",
    "\n",
    "print(\"np.exp( pds ):\\n\", np.exp( pds ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series from a dictionary\n",
    "\n",
    "Series are so close to a dictionary that you can create one from a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\n",
    "pds = pd.Series(sdata)\n",
    "\n",
    "print(pds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When passing also an index, this is used to filter matching entries of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['California', 'Ohio', 'Oregon', 'Texas']\n",
    "pds = pd.Series(sdata, index=states) # California is not in sdata\n",
    "\n",
    "print(pds) # Welcome missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `'Utah'` was not included, and that a special value `NaN` is used for the index `California`.\n",
    "\n",
    "Missing data is common, (e.g., movies withouth ratings), and usually `NaN` is used to represent them. \n",
    "\n",
    "It is possible to use `isnull` to find null values, and to replace them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series({'Ohio': 35000, 'Texas': 71000, \n",
    "                 'Oregon': 16000, 'Utah': 5000},\n",
    "               index=['Ohio', 'Texas', 'California'])\n",
    "\n",
    "print (pd.isnull(obj))\n",
    "print ()\n",
    "\n",
    "obj [ pd.isnull(obj) ] = 0.0\n",
    "\n",
    "print (obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively one can use the `fillna` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series({'Ohio': 35000, 'Texas': 71000, \n",
    "                 'Oregon': 16000, 'Utah': 5000},\n",
    "               index=['Ohio', 'Texas', 'California'])\n",
    "\n",
    "obj2 = obj.fillna(0.0) # returns a new data frame\n",
    "print (obj)\n",
    "print ()\n",
    "print (obj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj = pd.Series({'Ohio': 35000, 'Texas': 71000, \n",
    "                 'Oregon': 16000, 'Utah': 5000},\n",
    "               index=['Ohio', 'Texas', 'California'])\n",
    "\n",
    "obj.fillna(0.0, inplace=True) # inplace modification\n",
    "print (obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allignment by index\n",
    "\n",
    "A useful Series feature for many applications is that it automatically aligns by index\n",
    "label in arithmetic operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds1 = pd.Series({'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000})  # California is missing\n",
    "  \n",
    "pds2 = pd.Series({'California': 40000, 'Texas': 555, 'Oregon': 111, 'Utah': 222}) # Ohio is missing\n",
    "\n",
    "pds1 + pds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds1 = pd.Series({'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000})  # California is missing\n",
    "  \n",
    "pds2 = pd.Series({'California': 40000, 'Texas': 555, 'Oregon': 111, 'Utah': 222}) # Ohio is missing\n",
    "\n",
    "pds1.add(pds2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: List the player names, and count the number of matches they had\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_file = './datasets/tennis/2019.xlsx'\n",
    "df = pd.read_excel(dataset_file) \n",
    "\n",
    "players = df['Winner'].value_counts() + df['Loser'].value_counts()\n",
    "players.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "players = df['Winner'].value_counts().add(df['Loser'].value_counts(), fill_value=0)\n",
    "\n",
    "# Note: you can sort !\n",
    "players.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Selection, Addition, and Deletion\n",
    "\n",
    "Very similar to column operation , with a different way of specifying rows.\n",
    "\n",
    "More details at https://pandas.pydata.org/pandas-docs/stable/indexing.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example (Selection)\n",
    "We can access rows by using the index value in the special `loc` attribute.\n",
    "\n",
    "Note that the result is a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"Location\", inplace=True) # Alternative to df = df.set_index(\"Location\")\n",
    "\n",
    "df.loc['Brisbane'] # get all the mathing rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example (Selection)\n",
    "We can access rows by using a list of index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ ['Paris','London'] ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example (Selection)\n",
    "Rows can be selected by using integer location with the special `iloc` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example (Selection)\n",
    "Slicing over the rows with `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example (Addition)\n",
    "We can add a new row by using `loc` attribute.\n",
    "\n",
    "Pandas also `append` has function (see https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.append.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a smaller copy\n",
    "small_df = pd.DataFrame( df[ ['Surface', 'Winner', 'Loser'] ] ) \n",
    "small_df = small_df.loc[['London', 'Paris']]\n",
    "\n",
    "small_df.loc['Mestre'] = ['Clay', 'Claudio L.', 'Nadal R.']\n",
    "small_df.loc['Mestre'] = ['Clay', 'Claudio L.', 'Federer R.'] # This is a replace\n",
    "\n",
    "small_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example (Deletion)\n",
    "We can remove a row (or more) with `drop()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "small_df.drop(\"Mestre\", inplace=True) # axis=0 is the default\n",
    "small_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a smaller copy\n",
    "small_df = pd.DataFrame( df[ ['Surface', 'Winner', 'Loser'] ] ) \n",
    "small_df = small_df.loc[['London', 'Paris']]\n",
    "\n",
    "small_df.loc['Mestre'] = ['Clay', 'Claudio L.', 'Nadal R.']\n",
    "small_df.loc['Mestre'] = ['Clay', 'Claudio L.', 'Federer R.'] # This is a replace\n",
    "\n",
    "# Remove all matching rows\n",
    "small_df.drop([\"London\", \"Paris\"], inplace=True)\n",
    "small_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame\n",
    "\n",
    "There are many ways to construct a DataFrame, though one of the most common is from a dictionary of equal-length lists (or NumPy arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],\n",
    "        'year': [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        'population': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "\n",
    "df = pd.DataFrame(data) \n",
    "\n",
    "df.index.name = \"Progressive\"   # Set index name\n",
    "df.columns.name = 'Attributes'  # Set columns name\n",
    "\n",
    "df # Default index is 0...N-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],\n",
    "        'year': [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        'population': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "\n",
    "df = pd.DataFrame(data,\n",
    "                 index = ['xxx1','xxx2','xxx3','xxx4','xxx5','xxx6']) \n",
    "\n",
    "df.index.name   = \"Custom ID\"   # Set index name\n",
    "df.columns.name = 'Attributes'  # Set columns name\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pandas to numpy\n",
    "\n",
    "If you prefer working with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df.values\n",
    "print (type(m))\n",
    "print ()\n",
    "\n",
    "print (m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: Find Most unexpected result by Nadal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_file = './datasets/tennis/2019.xlsx'\n",
    "\n",
    "df = pd.read_excel(dataset_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadal_winner = df[ df['Winner']=='Nadal R.' ]\n",
    "nadal_winner = nadal_winner[['Winner', 'B365W']]\n",
    "nadal_winner.columns = ['Player','bet'] # see also rename function\n",
    "nadal_winner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadal_loser = df[ df['Loser']=='Nadal R.' ]\n",
    "nadal_loser = nadal_loser[['Loser', 'B365W']]\n",
    "nadal_loser.columns = ['Player','bet'] \n",
    "nadal_loser.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadal_matches = pd.concat([nadal_winner, nadal_loser])\n",
    "nadal_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadal_matches.sort_values(by='bet',ascending=False, inplace=True)\n",
    "nadal_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_id = nadal_matches.index[0]\n",
    "print (df.loc[match_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: how many times the player with the best ranking won the match?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_file = './datasets/tennis/2019.xlsx'\n",
    "\n",
    "df = pd.read_excel(dataset_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gt_r = df['WRank']>df['LRank']\n",
    "\n",
    "w_gt_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gt_r = w_gt_r.astype(int)\n",
    "\n",
    "w_gt_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_wins = w_gt_r.sum()\n",
    "\n",
    "total_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_matches, _ = df.shape\n",
    "\n",
    "total_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"The success rate of the best ranked player is\", round(100.0*total_wins/total_matches,2), \"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: how much would you gain or lose by always betting 10€ on the best ranked player?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_file = './datasets/tennis/2019.xlsx'\n",
    "\n",
    "df = pd.read_excel(dataset_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gt_r = df['WRank']>df['LRank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompose the following to understand each singles setps\n",
    "gains = ( (df['B365W'][w_gt_r]-1.0) * 5.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = (~w_gt_r).sum() * 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = gains - losses\n",
    "\n",
    "print (\"If always betting on the best ranked, the profit would be\", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional useful manipulation\n",
    "\n",
    "Suppose, for some reason, you want to invert name/surname order.\n",
    "\n",
    "That is, suppose you want to apply the same &custom* function to every element of a dataframe/series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fun (x):\n",
    "    tokens = x.split()\n",
    "    tokens = tokens[::-1]\n",
    "    new_x  = ' '.join(tokens)\n",
    "    return new_x\n",
    "\n",
    "# note the re-assiggnment\n",
    "df['Winner'] = df['Winner'].map(my_fun)\n",
    "\n",
    "df['Winner']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What is the surface with longest matches on average (more games)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[ ['W1', 'L1', 'W2', 'L2', 'W3', 'L3', 'W4', 'L4', 'W5', 'L5'] ]\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = sub_df.fillna(0.0)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['games'] = sub_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ ['Surface','games'] ].groupby('Surface').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables\n",
    "\n",
    "Similar to groupby, also columsn are grouped.\n",
    "\n",
    " - See https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot_table.html\n",
    " \n",
    "The function `pivot_table` has the following main parameters.\n",
    "\n",
    "| Param name | Description|\n",
    "|-|:-|\n",
    "| values  | The column to be aggregated |\n",
    "| index   | Column names used to create rows of the Pivot Table |\n",
    "| columns | Column names used to create cols of the Pivot Table  |\n",
    "| aggfunc | Aggregation function (e.g., `np.sum`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: Find the most successful player by surface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_file = './datasets/tennis/2019.xlsx'\n",
    "df = pd.read_excel(dataset_file) \n",
    "\n",
    "\n",
    "df.pivot_table(values=\"ATP\", # irrelevant\n",
    "               index=\"Winner\",\n",
    "               columns=\"Surface\",\n",
    "               aggfunc=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(values=\"ATP\", # irrelevant\n",
    "               index=\"Winner\",\n",
    "               columns=\"Surface\",\n",
    "               aggfunc=len,\n",
    "               fill_value=0.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins = df.pivot_table(values=\"ATP\", # irrelevant\n",
    "               index=\"Winner\",\n",
    "               columns=\"Surface\",\n",
    "               aggfunc=len,\n",
    "               fill_value=0.0 )\n",
    "wins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for surface in wins.columns:\n",
    "    print (wins[surface].sort_values(ascending=False).head(1))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: Find the player with the best success rate  by surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './datasets/tennis/2019.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-abab28af3880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./datasets/tennis/2019.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, parse_cols, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     return io.parse(\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, engine)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datasets/tennis/2019.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset_file = './datasets/tennis/2019.xlsx'\n",
    "df = pd.read_excel(dataset_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins = df.pivot_table(values=\"ATP\", # irrelevant\n",
    "               index=\"Winner\",\n",
    "               columns=\"Surface\",\n",
    "               aggfunc=len,\n",
    "               fill_value=0.0 )\n",
    "wins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = df.pivot_table(values=\"ATP\", # irrelevant\n",
    "               index=\"Loser\",\n",
    "               columns=\"Surface\",\n",
    "               aggfunc=len,\n",
    "               fill_value=0.0 )\n",
    "losses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = wins + losses\n",
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = wins.add(losses, fill_value=0)\n",
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins.loc['Nadal R.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses.loc['Nadal R.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.loc['Nadal R.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_rate = wins / total\n",
    "\n",
    "success_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_rate = wins / total\n",
    "success_rate.fillna(0.0, inplace=True)\n",
    "success_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_rate.loc['Nadal R.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_rate.loc['Thiem D.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for surface in success_rate:  # note: you do not need to use .columns\n",
    "    print (success_rate[surface].sort_values(ascending=False).head(1))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Useful stuff\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Joins\n",
    "\n",
    "#### Many-to-One join\n",
    "Consider the following two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], \n",
    "                    'data1': range(7)})\n",
    "\n",
    "df2 = pd.DataFrame({'key': ['a', 'b', 'd'], \n",
    "                    'data2': range(3)})\n",
    "\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in df1 has multiple rows labeled a and b, whereas df2 has only one row for each value in the key column. \n",
    "\n",
    "The operation \n",
    "\n",
    "```\n",
    "pd.merge(df1, df2, on='key')\n",
    "```\n",
    "\n",
    "will produce a merged DataFrame with key the column to join on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that \n",
    "- data2 of df2 is replicated everywhere key 'a' and 'b' occur in df1\n",
    "- rows with key 'c' in df1 and 'd' in df2 are not present in df\n",
    "\n",
    "The latter behavior is called **inner** join: the keys in the result are the intersection, or the common set found in both tables.\n",
    "\n",
    "Other possible approaches are: \n",
    "- **left**: keys of left DataFrame are kept\n",
    "- **right**: keys of right DataFrame are kept\n",
    "- **outer**: keys of both DataFrames are kept\n",
    "\n",
    "and can be chosen by setting parameter *how*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='key', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='key', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='key', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many-to-Many join\n",
    "Many-to-many merges happens when the same key has more than one occurrence in both DataFrames.\n",
    "\n",
    "Many-to-many joins form the Cartesian product of the rows having the same key. \n",
    "\n",
    "See the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key': ['b', 'b', 'a',  'a', 'b'], \n",
    "                    'data1': range(5)})\n",
    "                    \n",
    "df2 = pd.DataFrame({'key': ['a', 'b', 'a', 'b', 'd'],\n",
    "                    'data2': range(5)})\n",
    "                    \n",
    "pd.merge(df1, df2, on='key', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, since there were three 'b' rows in df1 and two in df2, there are six 'b' rows in the result.\n",
    "\n",
    "The merge can be performed also respect to more than one variable. To determine which key combinations will appear in the result depending on the choice of merge method, **think of the multiple keys as forming an array of tuples** to be used as a single join key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    " - **Python for Data Analysis**. O'Reilly. Wes McKinney.\n",
    "   - Section 5.1 (Indexing, Selection, and Filtering)\n",
    "   - Section 5.2 (Arithmetic and Data Alignment Function Application and Mapping Sorting and Ranking)\n",
    "   - Section 5.3 (Unique Values, Value Counts, and Membership)\n",
    "   - Section 10.4 (Pivot Tables)\n",
    "   - Section 14.5\n",
    "   - https://github.com/wesm/pydata-book\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
