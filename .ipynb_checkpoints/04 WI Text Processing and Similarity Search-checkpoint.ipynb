{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Intelligence\n",
    "# Text Processing and Similarity Search\n",
    "\n",
    "#### Prof. Claudio Lucchese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity search\n",
    "\n",
    "Similarity search is a fundamental task in Web and Data Mining. It's a building block for:\n",
    " - **Plagiarism Detection**. Consider newly published document that may infringe copyrights, including images and videos.\n",
    " - **Mirror Pages**. Crawled pages from a search engines may have 40% mirror pages.\n",
    " - **Recommendation Systems**. On-line purchases, Movies, Hotels, Restaurants, ...\n",
    " - **Person identification**. Personal devices, security monitoring, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Search in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source:\n",
    "    https://www.kaggle.com/mousehead/songlyrics\n",
    "\n",
    "**Task:\n",
    "Find the most similar song to \"Pink\" by Aerosmith**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_file = \"../datasets/lyrics/songdata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist,song,link,text\r\n",
      "ABBA,Ahe's My Kind Of Girl,/a/abba/ahes+my+kind+of+girl_20598417.html,\"Look at her face, it's a wonderful face  \r\n",
      "And it means something special to me  \r\n",
      "Look at the way that she smiles when she sees me  \r\n",
      "How lucky can one fellow be?  \r\n",
      "  \r\n",
      "She's just my kind of girl, she makes me feel fine  \r\n",
      "Who could ever believe that she could be mine?  \r\n",
      "She's just my kind of girl, without her I'm blue  \r\n",
      "And if she ever leaves me what could I do, what could I do?  \r\n"
     ]
    }
   ],
   "source": [
    "#linux only\n",
    "!head {songs_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist : ABBA\n",
      "song : Ahe's My Kind Of Girl\n",
      "link : /a/abba/ahes+my+kind+of+girl_20598417.html\n",
      "text : Look at her face, it's a wonderful face  \n",
      "And it means something special to me  \n",
      "Look at the way that she smiles when she sees me  \n",
      "How lucky can one fellow be?  \n",
      "  \n",
      "She's just my kind of girl, she makes me feel fine  \n",
      "Who could ever believe that she could be mine?  \n",
      "She's just my kind of girl, without her I'm blue  \n",
      "And if she ever leaves me what could I do, what could I do?  \n",
      "  \n",
      "And when we go for a walk in the park  \n",
      "And she holds me and squeezes my hand  \n",
      "We'll go on walking for hours and talking  \n",
      "About all the things that we plan  \n",
      "  \n",
      "She's just my kind of girl, she makes me feel fine  \n",
      "Who could ever believe that she could be mine?  \n",
      "She's just my kind of girl, without her I'm blue  \n",
      "And if she ever leaves me what could I do, what could I do?\n",
      "\n",
      "\n",
      "artist : ABBA\n",
      "song : Andante, Andante\n",
      "link : /a/abba/andante+andante_20002708.html\n",
      "text : Take it easy with me, please  \n",
      "Touch me gently like a summer evening breeze  \n",
      "Take your time, make it slow  \n",
      "Andante, Andante  \n",
      "Just let the feeling grow  \n",
      "  \n",
      "Make your fingers soft and light  \n",
      "Let your body be the velvet of the night  \n",
      "Touch my soul, you know how  \n",
      "Andante, Andante  \n",
      "Go slowly with me now  \n",
      "  \n",
      "I'm your music  \n",
      "(I am your music and I am your song)  \n",
      "I'm your song  \n",
      "(I am your music and I am your song)  \n",
      "Play me time and time again and make me strong  \n",
      "(Play me again 'cause you're making me strong)  \n",
      "Make me sing, make me sound  \n",
      "(You make me sing and you make me)  \n",
      "Andante, Andante  \n",
      "Tread lightly on my ground  \n",
      "Andante, Andante  \n",
      "Oh please don't let me down  \n",
      "  \n",
      "There's a shimmer in your eyes  \n",
      "Like the feeling of a thousand butterflies  \n",
      "Please don't talk, go on, play  \n",
      "Andante, Andante  \n",
      "And let me float away  \n",
      "  \n",
      "I'm your music  \n",
      "(I am your music and I am your song)  \n",
      "I'm your song  \n",
      "(I am your music and I am your song)  \n",
      "Play me time and time again and make me strong  \n",
      "(Play me again 'cause you're making me strong)  \n",
      "Make me sing, make me sound  \n",
      "(You make me sing and you make me)  \n",
      "Andante, Andante  \n",
      "Tread lightly on my ground  \n",
      "Andante, Andante  \n",
      "Oh please don't let me down  \n",
      "  \n",
      "Make me sing, make me sound  \n",
      "(You make me sing and you make me)  \n",
      "Andante, Andante  \n",
      "Tread lightly on my ground  \n",
      "Andante, Andante  \n",
      "Oh please don't let me down  \n",
      "Andante, Andante  \n",
      "Oh please don't let me down\n",
      "\n",
      "\n",
      "artist : ABBA\n",
      "song : As Good As New\n",
      "link : /a/abba/as+good+as+new_20003033.html\n",
      "text : I'll never know why I had to go  \n",
      "Why I had to put up such a lousy rotten show  \n",
      "Boy, I was tough, packing all my stuff  \n",
      "Saying I don't need you anymore, I've had enough  \n",
      "And now, look at me standing here again 'cause I found out that  \n",
      "Ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \n",
      "Gotta have you near  \n",
      "  \n",
      "As good as new, my love for you  \n",
      "And keeping it that way is my intention  \n",
      "As good as new and growing too  \n",
      "Yes, I think it's taking on a new dimension  \n",
      "It's as good as new, my love for you  \n",
      "Just like it used to be and even better  \n",
      "As good as new, thank God it's true  \n",
      "Darling, we were always meant to stay together  \n",
      "  \n",
      "Feel like a creep, never felt so cheap  \n",
      "Never had a notion that my love could be so deep  \n",
      "How could I make such a dumb mistake  \n",
      "Now I know I'm not entitled to another break  \n",
      "But please, baby, I beg you to forgive 'cause I found out that  \n",
      "Ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \n",
      "Gotta get you near  \n",
      "  \n",
      "I thought that our love was at an end but here I am again  \n",
      "  \n",
      "As good as new, my love for you  \n",
      "And keeping it that way is my intention  \n",
      "As good as new and growing too  \n",
      "Yes, I think it's taking on a new dimension  \n",
      "It's as good as new, my love for you  \n",
      "Just like it used to be and even better  \n",
      "As good as new, thank God it's true  \n",
      "Darling, we were always meant to stay together  \n",
      "  \n",
      "Yes the love I have for you feels as good as new  \n",
      "Darling, we were always meant to stay together\n",
      "\n",
      "\n",
      "artist : ABBA\n",
      "song : Bang\n",
      "link : /a/abba/bang_20598415.html\n",
      "text : Making somebody happy is a question of give and take  \n",
      "You can learn how to show it so come on, give yourself a break  \n",
      "Every smile and every little touch  \n",
      "Don't you know that they mean so much  \n",
      "Sweet sweet kisses so tender  \n",
      "Always will return to sender  \n",
      "  \n",
      "Like a bang, a boom-a-boomerang  \n",
      "Dum-be-dum-dum be-dum-be-dum-dum  \n",
      "Oh bang, a boom-a-boomerang  \n",
      "Love is a tune you hum-de-hum-hum  \n",
      "So give it away, I think you'll learn  \n",
      "You'll get love in return  \n",
      "So bang, a boom-a-boomerang is love  \n",
      "A boom-a-boomerang is love  \n",
      "  \n",
      "Love is always around and you can look for it anywhere  \n",
      "When you feel that you've found it my advice is to take good care  \n",
      "Never use it as a selfish tool  \n",
      "Never ever be such a fool  \n",
      "Every feeling you're showing  \n",
      "Is a boomerang you're throwing  \n",
      "  \n",
      "Yes a bang, a boom-a-boomerang  \n",
      "Dum-be-dum-dum be-dum-be-dum-dum  \n",
      "Oh bang, a boom-a-boomerang  \n",
      "Love is a tune you hum-de-hum-hum  \n",
      "So give it away, I think you'll learn  \n",
      "You'll get love in return  \n",
      "So bang, a boom-a-boomerang is love  \n",
      "  \n",
      "And if you're warm and tender  \n",
      "I'll kiss you, return to sender  \n",
      "Please surrender  \n",
      "  \n",
      "Bang, a boom-a-boomerang  \n",
      "Dum-be-dum-dum be-dum-be-dum-dum  \n",
      "Oh bang, a boom-a-boomerang is love  \n",
      "A boom-a-boomerang is love\n",
      "\n",
      "\n",
      "artist : ABBA\n",
      "song : Bang-A-Boomerang\n",
      "link : /a/abba/bang+a+boomerang_20002668.html\n",
      "text : Making somebody happy is a question of give and take  \n",
      "You can learn how to show it so come on, give yourself a break  \n",
      "Every smile and every little touch  \n",
      "Don't you know that they mean so much  \n",
      "Sweet sweet kisses so tender  \n",
      "Always will return to sender  \n",
      "  \n",
      "Like a bang, a boom-a-boomerang  \n",
      "Dumb-be-dumb-dumb be-dumb-be-dumb-dumb  \n",
      "Oh bang, a boom-a-boomerang  \n",
      "Love is a tune you hum-de-hum-hum  \n",
      "By giving away, I think you'll learn  \n",
      "You'll get love in return  \n",
      "So bang, a boom-a-boomerang is love  \n",
      "A boom-a-boomerang is love  \n",
      "  \n",
      "Love is always around and you can look for it anywhere  \n",
      "When you feel that you've found it my advice is to take good care  \n",
      "Never use it as a selfish tool  \n",
      "Never ever be such a fool  \n",
      "Every feeling you're showing  \n",
      "Is a boomerang you're throwing  \n",
      "  \n",
      "Yes a bang, a boom-a-boomerang  \n",
      "Dumb-be-dumb-dumb be-dumb-be-dumb-dumb  \n",
      "Oh bang, a boom-a-boomerang  \n",
      "Love is a tune you hum-de-hum-hum  \n",
      "By giving away, I think you'll learn  \n",
      "You'll get love in return  \n",
      "So bang, a boom-a-boomerang is love  \n",
      "  \n",
      "And if you're warm and tender  \n",
      "I'll kiss you, return to sender  \n",
      "Please surrender  \n",
      "  \n",
      "Bang, a boom-a-boomerang  \n",
      "Dumb-be-dumb-dumb be-dumb-be-dumb-dumb  \n",
      "Oh bang, a boom-a-boomerang is love  \n",
      "A boom-a-boomerang is love\n",
      "\n",
      "\n",
      "artist : ABBA\n",
      "song : Burning My Bridges\n",
      "link : /a/abba/burning+my+bridges_20003011.html\n",
      "text : Well, you hoot and you holler and you make me mad  \n",
      "And I've always been under your heel  \n",
      "Holy christ what a lousy deal  \n",
      "Now I'm sick and tired of your tedious ways  \n",
      "And I ain't gonna take it no more  \n",
      "Oh no no - walkin' out that door  \n",
      "  \n",
      "Burning my bridges, cutting my tie  \n",
      "Once again I wanna look into the eye  \n",
      "Being myself  \n",
      "Counting my pride  \n",
      "No un-right neighbour's gonna take me for a ride  \n",
      "Burning my bridges  \n",
      "Moving at last  \n",
      "Girl I'm leaving and I'm burying the past  \n",
      "Gonna have peace now  \n",
      "You can be free  \n",
      "No one here will make a sucker out of me\n",
      "\n",
      "\n",
      "artist : ABBA\n",
      "song : Cassandra\n",
      "link : /a/abba/cassandra_20002811.html\n",
      "text : Down in the street they're all singing and shouting  \n",
      "Staying alive though the city is dead  \n",
      "Hiding their shame behind hollow laughter  \n",
      "While you are crying alone on your bed  \n",
      "  \n",
      "Pity Cassandra that no one believed you  \n",
      "But then again you were lost from the start  \n",
      "Now we must suffer and sell our secrets  \n",
      "Bargain, playing smart, aching in our hearts  \n",
      "  \n",
      "Sorry Cassandra I misunderstood  \n",
      "Now the last day is dawning  \n",
      "Some of us wanted but none of us would  \n",
      "Listen to words of warning  \n",
      "But on the darkest of nights  \n",
      "Nobody knew how to fight  \n",
      "And we were caught in our sleep  \n",
      "Sorry Cassandra I didn't believe  \n",
      "You really had the power  \n",
      "I only saw it as dreams you would weave  \n",
      "Until the final hour  \n",
      "  \n",
      "So in the morning your ship will be sailing  \n",
      "Now that your father and sister are gone  \n",
      "There is no reason for you to linger  \n",
      "You're grieving deeply but still moving on  \n",
      "  \n",
      "You know the future is casting a shadow  \n",
      "No one else sees it but you know your fate  \n",
      "Packing your bags, being slow and thorough  \n",
      "Knowing, though you're late, that ship is sure to wait  \n",
      "  \n",
      "Sorry Cassandra I misunderstood  \n",
      "Now the last day is dawning  \n",
      "Some of us wanted but none of us would  \n",
      "Listen to words of warning  \n",
      "But on the darkest of nights  \n",
      "Nobody knew how to fight  \n",
      "And we were caught in our sleep  \n",
      "Sorry Cassandra I didn't believe  \n",
      "You really had the power  \n",
      "I only saw it as dreams you would weave  \n",
      "Until the final hour  \n",
      "  \n",
      "I watched the ship leaving harbor at sunrise  \n",
      "Sails almost slack in the cool morning rain  \n",
      "She stood on deck, just a tiny figure  \n",
      "Rigid and restrained, blue eyes filled with pain  \n",
      "  \n",
      "Sorry Cassandra I misunderstood  \n",
      "Now the last day is dawning  \n",
      "Some of us wanted but none of us would  \n",
      "Listen to words of warning  \n",
      "But on the darkest of nights  \n",
      "Nobody knew how to fight  \n",
      "And we were caught in our sleep  \n",
      "Sorry Cassandra I didn't believe  \n",
      "You really had the power  \n",
      "I only saw it as dreams you would weave  \n",
      "Until the final hour  \n",
      "  \n",
      "I'm sorry Cassandra  \n",
      "I'm sorry Cassandra\n",
      "\n",
      "\n",
      "artist : ABBA\n",
      "song : Chiquitita\n",
      "link : /a/abba/chiquitita_20002978.html\n",
      "text : Chiquitita, tell me what's wrong  \n",
      "You're enchained by your own sorrow  \n",
      "In your eyes there is no hope for tomorrow  \n",
      "How I hate to see you like this  \n",
      "There is no way you can deny it  \n",
      "I can see that you're oh so sad, so quiet  \n",
      "  \n",
      "Chiquitita, tell me the truth  \n",
      "I'm a shoulder you can cry on  \n",
      "Your best friend, I'm the one you must rely on  \n",
      "You were always sure of yourself  \n",
      "Now I see you've broken a feather  \n",
      "I hope we can patch it up together  \n",
      "  \n",
      "Chiquitita, you and I know  \n",
      "How the heartaches come and they go and the scars they're leaving  \n",
      "You'll be dancing once again and the pain will end  \n",
      "You will have no time for grieving  \n",
      "Chiquitita, you and I cry  \n",
      "But the sun is still in the sky and shining above you  \n",
      "Let me hear you sing once more like you did before  \n",
      "Sing a new song, Chiquitita  \n",
      "Try once more like you did before  \n",
      "Sing a new song, Chiquitita  \n",
      "  \n",
      "So the walls came tumbling down  \n",
      "And your love's a blown out candle  \n",
      "All is gone and it seems too hard to handle  \n",
      "Chiquitita, tell me the truth  \n",
      "There is no way you can deny it  \n",
      "I see that you're oh so sad, so quiet  \n",
      "  \n",
      "Chiquitita, you and I know  \n",
      "How the heartaches come and they go and the scars they're leaving  \n",
      "You'll be dancing once again and the pain will end  \n",
      "You will have no time for grieving  \n",
      "Chiquitita, you and I cry  \n",
      "But the sun is still in the sky and shining above you  \n",
      "Let me hear you sing once more like you did before  \n",
      "Sing a new song, Chiquitita  \n",
      "Try once more like you did before  \n",
      "Sing a new song, Chiquitita  \n",
      "Try once more like you did before  \n",
      "Sing a new song, Chiquitita\n",
      "\n",
      "\n",
      "artist : ABBA\n",
      "song : Crazy World\n",
      "link : /a/abba/crazy+world_20003013.html\n",
      "text : I was out with the morning sun  \n",
      "Couldn't sleep, so I thought I'd take a walk  \n",
      "I was thinking of you and me  \n",
      "And I went to your house, 'cause I had to talk  \n",
      "  \n",
      "I could hardly believe my eyes  \n",
      "When I saw this guy closing your front door  \n",
      "Had the feeling of emptiness like I never had before  \n",
      "And I closed my eyes, will you leave me girl  \n",
      "  \n",
      "Then I realized, it's a crazy world  \n",
      "As he disapeared in his car  \n",
      "I was stunned and I didn't know what to do  \n",
      "Everything I had ever dreamed  \n",
      "  \n",
      "Everything in my life's part of you  \n",
      "And I just couldn't move my feet  \n",
      "So I stood on the pavement as you came out  \n",
      "You acted as you didn't know what it was all about  \n",
      "  \n",
      "And I closed my eyes, will you leave me girl  \n",
      "Then I realized, it's a crazy world  \n",
      "Baby, how could you do it  \n",
      "You just told me lies  \n",
      "  \n",
      "And you meet behind my back  \n",
      "With other guys  \n",
      "Baby, how could you tell me  \n",
      "There was only me  \n",
      "  \n",
      "I was stupid to believe you  \n",
      "I was blind but now I see  \n",
      "Then you smiled and you took my hand  \n",
      "\"There is something\", you said, \"that you may not know  \n",
      "  \n",
      "There's a couple of men in my life  \n",
      "And one of them is my brother Joe  \n",
      "He's been gone for a long, long time  \n",
      "But he's back and I think he's gonna stay  \n",
      "  \n",
      "You'll be seeing a lot of him, he's so nice in every way\"  \n",
      "Then I closed my eyes, never leave me girl  \n",
      "Then I realized, it's a crazy world  \n",
      "So I closed my eyes, never leave me girl  \n",
      "  \n",
      "Then I realized, it's a crazy world  \n",
      "So I closed my eyes, never leave me girl  \n",
      "Then I realized, it's a crazy world\n",
      "\n",
      "\n",
      "artist : ABBA\n",
      "song : Crying Over You\n",
      "link : /a/abba/crying+over+you_20177611.html\n",
      "text : I'm waitin' for you baby  \n",
      "I'm sitting all alone  \n",
      "I feel so cold without you  \n",
      "It chills me to the bone  \n",
      "I never thought you'd leave me  \n",
      "But now I know it's true  \n",
      "Oh Lord I'm blue  \n",
      "I'm cryin' over you  \n",
      "I'm waitin' for you baby  \n",
      "I'm sittin' all alone  \n",
      "I feel so cold without you  \n",
      "It chills me to the bone  \n",
      "I never thought you'd leave me  \n",
      "But now I know it's true  \n",
      "Oh Lord I'm blue  \n",
      "I'm cryin' over you  \n",
      "  \n",
      "Cryin' over you  \n",
      "I'm cryin' over you  \n",
      "Cryin' over  \n",
      "Little memories of things we used to do  \n",
      "Oh Lord I'm blue  \n",
      "I'm cryin' over you  \n",
      "Oh Lord I'm blue  \n",
      "I'm cryin' over you  \n",
      "Oh Lord I'm blue  \n",
      "I'm cryin' over you\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tentative: read the first 10 lines and inspect the content\n",
    "\n",
    "import csv\n",
    "# see DickReader https://docs.python.org/3/library/csv.html\n",
    "\n",
    "with open(songs_file, newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for i,row in enumerate(reader):\n",
    "        if i==10:break\n",
    "        for k,v in row.items():\n",
    "            print (k,\":\",v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all dataset in memory\n",
    "\n",
    "**Disclaimer**: in the following we limit the number of songs to make sure we have enough memory and reasonable running times. It's clear that \n",
    "**the more songs the more interesting the result**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist: ABBA\n",
      "title: Ahe's My Kind Of Girl\n",
      "lyrics: Look at her face, it's a wonderful face  \n",
      "And it means something special to me  \n",
      "Look at the way that she smiles when she sees me  \n",
      "How lucky can one fellow be?  \n",
      "  \n",
      "She's just my kind of girl, she makes me feel fine  \n",
      "Who could ever believe that she could be mine?  \n",
      "She's just my kind of girl, without her I'm blue  \n",
      "And if she ever leaves me what could I do, what could I do?  \n",
      "  \n",
      "And when we go for a walk in the park  \n",
      "And she holds me and squeezes my hand  \n",
      "We'll go on walking for hours and talking  \n",
      "About all the things that we plan  \n",
      "  \n",
      "She's just my kind of girl, she makes me feel fine  \n",
      "Who could ever believe that she could be mine?  \n",
      "She's just my kind of girl, without her I'm blue  \n",
      "And if she ever leaves me what could I do, what could I do?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, max_songs = 5000):\n",
    "    rows = []\n",
    "\n",
    "    with open(filename, newline='') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for i,row in enumerate(reader):\n",
    "            rows += [ [x for x in row.values()] ]\n",
    "            if len(rows)>=max_songs:\n",
    "                break\n",
    "    return rows\n",
    "\n",
    "raw_dataset = load_data(songs_file)\n",
    "\n",
    "print (\"artist:\", raw_dataset[0][0])\n",
    "print (\"title:\",  raw_dataset[0][1])\n",
    "print (\"lyrics:\", raw_dataset[0][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for \"Pink\" by Aerosmith\n",
    "\n",
    "Try with another song of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 Aerosmith Pink\n",
      "780 Ariana Grande Pink Champagne\n",
      "2126 Cake Pretty Pink Ribbon\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(raw_dataset):\n",
    "    if \"Pink\" in row[1]:\n",
    "        print(i,row[0],row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pink, it's my new obsession, yeah  \n",
      "Pink, it's not even a question  \n",
      "Pink, on the lips of your lover  \n",
      "'Cause pink is the love you discover  \n",
      "Pink, as the bing on your cherry  \n",
      "Pink, 'cause you are so very  \n",
      "Pink, it's the color of passion  \n",
      "  \n",
      "'Cause today it just goes with the fashion  \n",
      "Pink, it was love at first sight  \n",
      "Yeah pink, when I turn out the light  \n",
      "And pink gets me high as a kite  \n",
      "And I think everything is going to be alright  \n",
      "No matter what we do tonight  \n",
      "  \n",
      "You could be my flamingo  \n",
      "'Cause pink, it's a new kinda lingo  \n",
      "Pink, like a deco umbrella  \n",
      "Ffff, it's kink that you don't ever tell her  \n",
      "Yeah, pink, it was love at first sight  \n",
      "Then pink when I turn out the light  \n",
      "Yeah, pink gets me high as a kite  \n",
      "And I think everything is going to be alright  \n",
      "No matter what we do tonight  \n",
      "  \n",
      "Yeah,  \n",
      "I, want to be your lover  \n",
      "Ffff, I I wanna wrap you in rubber  \n",
      "And it's pink as the sheets that we lay on  \n",
      "'Cause pink, It's my favorite crayon  \n",
      "  \n",
      "Yeah  \n",
      "Pink, it was love at first sight, yeah  \n",
      "Pink, when I turn out the light  \n",
      "Yeah pink, it's like red but not quite  \n",
      "And I think everything is going to be alright  \n",
      "No matter what we do tonight\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (raw_dataset[183][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 Aerosmith Pink\n",
      "780 Ariana Grande Pink Champagne\n",
      "2126 Cake Pretty Pink Ribbon\n"
     ]
    }
   ],
   "source": [
    "for i,(a,t,u,l) in enumerate(raw_dataset):\n",
    "    if \"Pink\" in t:\n",
    "        print(i,a,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the query song\n",
    "query_id = 183\n",
    "skip = [] # if any, put covers here !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pink, it's my new obsession, yeah  \n",
      "Pink, it's not even a question  \n",
      "Pink, on the lips of your lover  \n",
      "'Cause pink is the love you discover  \n",
      "Pink, as the bing on your cherry  \n",
      "Pink, 'cause you are so very  \n",
      "Pink, it's the color of passion  \n",
      "  \n",
      "'Cause today it just goes with the fashion  \n",
      "Pink, it was love at first sight  \n",
      "Yeah pink, when I turn out the light  \n",
      "And pink gets me high as a kite  \n",
      "And I think everything is going to be alright  \n",
      "No matter what we do tonight  \n",
      "  \n",
      "You could be my flamingo  \n",
      "'Cause pink, it's a new kinda lingo  \n",
      "Pink, like a deco umbrella  \n",
      "Ffff, it's kink that you don't ever tell her  \n",
      "Yeah, pink, it was love at first sight  \n",
      "Then pink when I turn out the light  \n",
      "Yeah, pink gets me high as a kite  \n",
      "And I think everything is going to be alright  \n",
      "No matter what we do tonight  \n",
      "  \n",
      "Yeah,  \n",
      "I, want to be your lover  \n",
      "Ffff, I I wanna wrap you in rubber  \n",
      "And it's pink as the sheets that we lay on  \n",
      "'Cause pink, It's my favorite crayon  \n",
      "  \n",
      "Yeah  \n",
      "Pink, it was love at first sight, yeah  \n",
      "Pink, when I turn out the light  \n",
      "Yeah pink, it's like red but not quite  \n",
      "And I think everything is going to be alright  \n",
      "No matter what we do tonight\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ( raw_dataset[query_id][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to find the most similar song?\n",
    "\n",
    "We need two ingredients:\n",
    " - define what is a song?\n",
    " - define when two songs are similar\n",
    " \n",
    "better:\n",
    " - define a **representation** for the song\n",
    " - define a **similarity** function \n",
    "\n",
    "\n",
    "Representation and similarity are two key ingredients in several data mining tasks, e.g., collaborative filtering, clustering, etc. Beyond the limitations of the example below, you should first design a suitable similarity function, and then find a good representation to implement such similarity function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1\n",
    "\n",
    " - A song is a **set of words**\n",
    " - Similarity is given by the **number of shared words**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the set of words of each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABBA Ahe's My Kind Of Girl\n"
     ]
    }
   ],
   "source": [
    "print (raw_dataset[0][0], raw_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look at her face, it's a wonderful face  \n",
      "And it means something special to me  \n",
      "Look at the way that she smiles when she sees me  \n",
      "How lucky can one fellow be?  \n",
      "  \n",
      "She's just my kind of girl, she makes me feel fine  \n",
      "Who could ever believe that she could be mine?  \n",
      "She's just my kind of girl, without her I'm blue  \n",
      "And if she ever leaves me what could I do, what could I do?  \n",
      "  \n",
      "And when we go for a walk in the park  \n",
      "And she holds me and squeezes my hand  \n",
      "We'll go on walking for hours and talking  \n",
      "About all the things that we plan  \n",
      "  \n",
      "She's just my kind of girl, she makes me feel fine  \n",
      "Who could ever believe that she could be mine?  \n",
      "She's just my kind of girl, without her I'm blue  \n",
      "And if she ever leaves me what could I do, what could I do?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (raw_dataset[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on', 'something', 'my', 'I', 'in', 'blue', 'walk', 'it', 'special', 'one', 'Look', 'way', 'can', 'be?', 'mine?', 'if', 'we', 'that', \"We'll\", 'Who', 'just', 'leaves', 'things', \"I'm\", 'she', 'to', 'fellow', 'fine', 'face,', 'feel', 'without', 'makes', 'what', 'her', 'could', 'talking', 'squeezes', 'smiles', 'park', 'plan', 'About', 'be', 'and', 'walking', 'holds', 'at', 'kind', 'hand', 'for', 'the', 'do,', 'when', 'all', 'believe', 'lucky', 'me', 'means', 'do?', 'sees', 'ever', 'go', 'face', 'And', 'How', 'girl,', 'a', 'of', 'wonderful', 'hours', \"She's\", \"it's\"}\n"
     ]
    }
   ],
   "source": [
    "# Python allows sets !\n",
    "print ( set(raw_dataset[0][-1].split()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on', 'something', 'my', 'I', 'in', 'blue', 'walk', 'it', 'special', 'one', 'Look', 'way', 'can', 'be?', 'mine?', 'if', 'we', 'that', \"We'll\", 'Who', 'just', 'leaves', 'things', \"I'm\", 'she', 'to', 'fellow', 'fine', 'face,', 'feel', 'without', 'makes', 'what', 'her', 'could', 'talking', 'squeezes', 'smiles', 'park', 'plan', 'About', 'be', 'and', 'walking', 'holds', 'at', 'kind', 'hand', 'for', 'the', 'do,', 'when', 'all', 'believe', 'lucky', 'me', 'means', 'do?', 'sees', 'ever', 'go', 'face', 'And', 'How', 'girl,', 'a', 'of', 'wonderful', 'hours', \"She's\", \"it's\"}\n"
     ]
    }
   ],
   "source": [
    "def get_words (songs):\n",
    "    songs_words = []\n",
    "    for s in songs:\n",
    "        lyrics = s[-1]         # this is a string\n",
    "        words = lyrics.split() # this is a list\n",
    "        words = set(words)     # create a set\n",
    "        songs_words += [words] # append words to the list\n",
    "    return songs_words\n",
    "\n",
    "\n",
    "lyrics_word_split = get_words(raw_dataset)\n",
    "\n",
    "print ( lyrics_word_split[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on', 'something', 'my', 'I', 'in', 'blue', 'walk', 'it', 'special', 'one', 'Look', 'way', 'can', 'be?', 'mine?', 'if', 'we', 'that', \"We'll\", 'Who', 'just', 'leaves', 'things', \"I'm\", 'she', 'to', 'fellow', 'fine', 'face,', 'feel', 'without', 'makes', 'what', 'her', 'could', 'talking', 'squeezes', 'smiles', 'park', 'plan', 'About', 'be', 'and', 'walking', 'holds', 'at', 'kind', 'hand', 'for', 'the', 'do,', 'when', 'all', 'believe', 'lucky', 'me', 'means', 'do?', 'sees', 'ever', 'go', 'face', 'And', 'How', 'girl,', 'a', 'of', 'wonderful', 'hours', \"She's\", \"it's\"}\n"
     ]
    }
   ],
   "source": [
    "# As above, but in one line\n",
    "def get_words (songs):\n",
    "    return [ set(s[-1].split()) for s in songs ]\n",
    "\n",
    "lyrics_word_split = get_words(raw_dataset)\n",
    "\n",
    "print ( lyrics_word_split[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on', 'Yeah', 'we', 'not', 'tell', 'Pink,', 'that', 'just', 'wrap', 'sight', \"don't\", \"'Cause\", 'her', 'light', 'today', 'lips', 'the', 'when', 'umbrella', 'crayon', 'Ffff,', 'ever', 'favorite', 'pink', 'sight,', 'You', 'matter', 'lingo', 'bing', 'to', 'tonight', 'could', 'fashion', 'with', 'going', 'kinda', 'obsession,', 'goes', 'turn', 'your', 'be', 'very', 'passion', 'me', 'like', 'gets', 'deco', 'red', 'And', 'rubber', 'of', 'I', 'sheets', 'No', 'everything', 'even', 'you', 'what', 'cherry', \"It's\", 'high', 'wanna', 'first', 'at', 'want', 'as', 'flamingo', 'was', 'new', 'kite', 'my', 'Yeah,', 'love', 'in', 'are', 'it', 'lay', 'pink,', 'think', 'but', 'lover', 'is', 'I,', 'quite', 'Then', 'so', 'question', 'color', 'alright', \"'cause\", 'out', 'discover', 'do', 'yeah', 'kink', 'a', \"it's\"}\n"
     ]
    }
   ],
   "source": [
    "print (lyrics_word_split[query_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test similarity\n",
    "print ( lyrics_word_split[0] & lyrics_word_split[query_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( len(lyrics_word_split[0] & lyrics_word_split[query_id]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def most_similar_by_words(s, songs, skip_list):\n",
    "    most_similar = None\n",
    "    largest_similarity = 0.0\n",
    "    \n",
    "    for s_id, s_text in enumerate(songs):\n",
    "        \n",
    "        if s_id == query_id: continue\n",
    "        if s_id in skip_list: continue\n",
    "        \n",
    "        # compute number of common words\n",
    "        sim = len(s_text & songs[s])      \n",
    "\n",
    "        if sim>=largest_similarity:\n",
    "            most_similar = s_id\n",
    "            largest_similarity = sim\n",
    "    \n",
    "    return most_similar, largest_similarity\n",
    "\n",
    "sim_id, sim_value = most_similar_by_words(query_id, lyrics_word_split, skip)\n",
    "\n",
    "print (\"Most similar song is:\", sim_id)\n",
    "print (\"Similarity is:\", sim_value)\n",
    "print (\"Artist:\", raw_dataset[sim_id][0])\n",
    "print (\"Title:\", raw_dataset[sim_id][1])\n",
    "print (\"Lyrics:\", raw_dataset[sim_id][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we do it in one line of code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a small check\n",
    "print ( max([1,2,3]) )\n",
    "print ( max([(2,1),(2,2),(1,3)]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Exercise\n",
    "\n",
    "def most_similar_by_words(s, songs, skiplist):\n",
    "    most_similar = max( [ (len(s_text & songs[s]), s_id) \n",
    "                             for s_id, s_text in enumerate(songs) \n",
    "                             if s_id not in skiplist ]   )\n",
    "    return most_similar[1], most_similar[0]\n",
    "\n",
    "    \n",
    "sim_id, sim_value = most_similar_by_words(query_id, lyrics_word_split, \n",
    "                                          set(skip+[query_id]))\n",
    "\n",
    "print (\"Most similar song is:\", sim_id)\n",
    "print (\"Similarity is:\", sim_value)\n",
    "print (\"Artist:\", raw_dataset[sim_id][0])\n",
    "print (\"Title:\", raw_dataset[sim_id][1])\n",
    "print (\"Lyrics:\", raw_dataset[sim_id][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just too many words in this song ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some exercises:\n",
    " - longest song\n",
    " - shortest song\n",
    " - song with most unique terms\n",
    " - song with least unique terms\n",
    " - artist with most songs\n",
    " - artist with most unique terms\n",
    " - how many unique terms in all songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard similarity\n",
    "\n",
    "\n",
    "$$\n",
    "J(A,B) = \\frac{|A\\cap B|}{|A \\cup B|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a,b):\n",
    "    return len(a & b) / len( a | b)\n",
    "\n",
    "print ( jaccard( set([1,2,3]), set([2,3,4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_jaccard(s, songs, skiplist):\n",
    "    most_similar = max( [ (jaccard(s_text, songs[s]), s_id) \n",
    "                             for s_id, s_text in enumerate(songs) \n",
    "                             if s_id not in skiplist ]   )\n",
    "    return most_similar[1], most_similar[0]\n",
    "\n",
    "sim_id, sim_value = most_similar_jaccard(query_id, lyrics_word_split, \n",
    "                                         set(skip+[query_id]))\n",
    "\n",
    "print (\"Most similar song is:\", sim_id)\n",
    "print (\"Similarity is:\", sim_value)\n",
    "print (\"Artist:\", raw_dataset[sim_id][0])\n",
    "print (\"Title:\", raw_dataset[sim_id][1])\n",
    "print (\"Lyrics:\", raw_dataset[sim_id][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (raw_dataset[query_id][0])\n",
    "print (raw_dataset[query_id][1])\n",
    "print (raw_dataset[query_id][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lyrics_word_split[query_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1: Tokenization\n",
    "\n",
    "Text Processing library: https://textblob.readthedocs.io/en/dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# if the above command is not working\n",
    "# execute below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linux\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install TextBlob\n",
    "\n",
    "# windows try\n",
    "# pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob(raw_dataset[query_id][-1])\n",
    "\n",
    "TextBlob(raw_dataset[query_id][-1]).lower()\n",
    "\n",
    "TextBlob(raw_dataset[query_id][-1]).lower().words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens (songs):\n",
    "    return [ set(TextBlob(song[-1]).lower().words) for song in songs ]\n",
    "\n",
    "lyrics_tokens = get_tokens(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( sorted(lyrics_word_split[query_id] ) )\n",
    "print ()\n",
    "print ( sorted(lyrics_tokens[query_id] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_id, sim_value = most_similar_jaccard(query_id, lyrics_tokens, \n",
    "                                         set(skip+[query_id]))\n",
    "\n",
    "print (\"Most similar song is:\", sim_id)\n",
    "print (\"Similarity is:\", sim_value)\n",
    "print (\"Artist:\", raw_dataset[sim_id][0])\n",
    "print (\"Title:\", raw_dataset[sim_id][1])\n",
    "print (\"Lyrics:\", raw_dataset[sim_id][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2: Stemming, Lemmatization\n",
    "\n",
    "Stemming refers to the removal of prefix/suffixes: `being` -> `be`, `was`->`was` \n",
    "\n",
    "Lemming refers to the identification of the \"origin\" of a word: `being` -> `be`, `was`->`be`\n",
    "\n",
    "\n",
    "The task is quite difficult, there might be errors anyway ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( sorted(set(TextBlob(raw_dataset[query_id][-1]).lower().words.stem() ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stems (songs):\n",
    "    return [ set(TextBlob(song[-1]).lower().words.stem()) for song in raw_dataset ]\n",
    "\n",
    "lyrics_stems = get_stems(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( sorted(lyrics_stems[query_id] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_id, sim_value = most_similar_jaccard(query_id, lyrics_stems, set(skip+[query_id]))\n",
    "\n",
    "print (\"Most similar song is:\", sim_id)\n",
    "print (\"Similarity is:\", sim_value)\n",
    "print (\"Artist:\", raw_dataset[sim_id][0])\n",
    "print (\"Title:\", raw_dataset[sim_id][1])\n",
    "print (\"Lyrics:\", raw_dataset[sim_id][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( lyrics_stems[sim_id] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( sorted( lyrics_stems[sim_id] & lyrics_stems[query_id]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    " - find the pair of songs whose similarity that was most affected by the stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 3: Term Frequency and Inverse Document Frequency\n",
    "\n",
    "\n",
    "We want to take into account the number of occurences of terms. Therefore we need to change our representation:\n",
    " - A song is vector of occurences\n",
    " - Similarity is ...\n",
    " \n",
    " \n",
    "To do so, we use a large matrix #songs x #terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise: find the lexicon\n",
    "\n",
    "\n",
    "lexicon = set([])\n",
    "for song in lyrics_stems:\n",
    "    lexicon |= set(song)\n",
    "\n",
    "print (len(lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_map     = {term:id for id,term in enumerate(lexicon)}\n",
    "lexicon_rev_map = {id:term for term,id in lexicon_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_map['pink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_rev_map[6686]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use numpy for matrix-based computations\n",
    "\n",
    "http://www.numpy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "lyrics_vector_space = np.zeros((len(lyrics_stems), len(lexicon)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_vector_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_vector_space.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_space (songs, lex_map):\n",
    "    m = np.zeros((len(songs), len(lex_map)))\n",
    "\n",
    "    for song_id, (s,t,l,song_text) in enumerate(songs):\n",
    "        for stem in TextBlob(song_text).lower().words.stem():\n",
    "            if stem in lex_map:\n",
    "                term_id = lex_map[stem]\n",
    "                m[song_id,term_id] += 1.0\n",
    "    \n",
    "    return m\n",
    "\n",
    "lyrics_vector_space = get_vector_space(raw_dataset, lexicon_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_vector_space[query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(lyrics_vector_space[query_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_vector_space[query_id]!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(lyrics_vector_space[query_id]!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lyrics_stems[query_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, numbers look consistent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What kind of similarity we can use ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is euclidean ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try with euclidean\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([1,5,7])\n",
    "\n",
    "print (a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( (a-b)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( np.sum((a-b)**2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( np.sqrt(np.sum((a-b)**2)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(a,b):\n",
    "    return np.sqrt( np.sum((a-b)**2.0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_euclidean(s, songs, skiplist):\n",
    "    num_songs, num_terms = songs.shape\n",
    "    most_similar = min( [ (euclidean(songs[s], songs[s_id]), s_id) \n",
    "                             for s_id in range(num_songs) \n",
    "                             if s_id not in skiplist ]   )\n",
    "    return most_similar[1], most_similar[0]\n",
    "\n",
    "sim_id, sim_value = most_similar_euclidean(query_id, lyrics_vector_space, \n",
    "                                           set(skip+[query_id]))\n",
    "\n",
    "print (\"Most similar song is:\", sim_id)\n",
    "print (\"Similarity is:\", sim_value)\n",
    "print (\"Artist:\", raw_dataset[sim_id][0])\n",
    "print (\"Title:\", raw_dataset[sim_id][1])\n",
    "print (\"Lyrics:\", raw_dataset[sim_id][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( sorted(lyrics_stems[sim_id] & lyrics_stems[query_id]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Space for proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What we need is Cosine Similarity\n",
    "\n",
    "\n",
    "$$\n",
    "\\cos(A,B)= \\frac{A \\cdot B}{\\|A\\| \\|B\\|} = \\frac{\\sum_i A_i B_i}{\\sqrt{\\sum_i A_i^2}\\sqrt{\\sum_i B_i^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(a,b):\n",
    "    return np.dot(a,b)/( np.sqrt( np.sum(a**2.0) ) * np.sqrt( np.sum(b**2.0) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine( np.array([1,0]), np.array([0,1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine( np.array([1,0]), np.array([2,0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_cosine(s, songs, skiplist):\n",
    "    num_songs, num_terms = songs.shape\n",
    "    most_similar = max( [ (cosine(songs[s], songs[s_id]), s_id) \n",
    "                             for s_id in range(num_songs) \n",
    "                             if s_id not in skiplist ]   )\n",
    "    return most_similar[1], most_similar[0]\n",
    "\n",
    "sim_id, sim_value = most_similar_cosine(query_id, lyrics_vector_space, set(skip+[query_id]))\n",
    "\n",
    "print (\"Most similar song is:\", sim_id)\n",
    "print (\"Similarity is:\", sim_value)\n",
    "print (\"Artist:\", raw_dataset[sim_id][0])\n",
    "print (\"Title:\", raw_dataset[sim_id][1])\n",
    "print (\"Lyrics:\", raw_dataset[sim_id][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's investigate the words that contribute most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized prod instead of dot product\n",
    "\n",
    "def norm_prod(a,b):\n",
    "    return a*b/( np.sqrt( np.sum(a**2.0) ) * np.sqrt( np.sum(b**2.0) ) )\n",
    "\n",
    "p = norm_prod(lyrics_vector_space[sim_id], lyrics_vector_space[query_id])\n",
    "print (len(p), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(p)\n",
    "print (idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = np.array([1,3,5,4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova[ np.argsort(prova) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova[ np.argsort(prova)[::-1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[idx[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term_id in np.argsort(idx)[::-1]:\n",
    "    if p[term_id]>0:\n",
    "        print (lexicon_rev_map[term_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse document frequency\n",
    "\n",
    "Inverse document frequency approximates the specificity of a term in a given document collection.\n",
    "IDF is defined as follows:\n",
    "\n",
    "$$\n",
    "idf(t) = \\ln \\frac{N_{docs}}{df(t)}\n",
    "$$\n",
    "\n",
    "where $N_{docs}$ is the number of documents in the collection and ${df(t)}$ is the number of documents containing the term $t$.\n",
    "\n",
    "IDF is used to discount frequent terms.\n",
    "\n",
    "The weight of a term for a document is thus defined as $tf(t)\\cdot idf(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sum = np.sum(lyrics_vector_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (m_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_vector_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sum = np.sum(lyrics_vector_space, axis=1)\n",
    "print (m_sum)\n",
    "print (m_sum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sum = np.sum(lyrics_vector_space, axis=0)\n",
    "print (m_sum)\n",
    "print (m_sum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sum = np.sum(lyrics_vector_space>0, axis=0)\n",
    "print (m_sum)\n",
    "print (m_sum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do a small test\n",
    "\n",
    "A = np.array([ [1,2,3], [4,5,6] ])\n",
    "b = np.array([1,2,3])\n",
    "\n",
    "print (A)\n",
    "print (b)\n",
    "print (A*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.sum(A/b>2, axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs, _ = lyrics_vector_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_tdif = lyrics_vector_space * np.log( num_docs/m_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_cosine(s, songs, skiplist):\n",
    "    num_songs, num_terms = songs.shape\n",
    "    most_similar = max( [ (cosine(songs[s], songs[s_id]), s_id) \n",
    "                             for s_id in range(num_songs) \n",
    "                             if s_id not in skiplist ]   )\n",
    "    return most_similar[1], most_similar[0]\n",
    "\n",
    "sim_id, sim_value = most_similar_cosine(query_id, lyrics_tdif, set(skip+[query_id]))\n",
    "\n",
    "print (\"Most similar song is:\", sim_id)\n",
    "print (\"Similarity is:\", sim_value)\n",
    "print (\"Artist:\", raw_dataset[sim_id][0])\n",
    "print (\"Title:\", raw_dataset[sim_id][1])\n",
    "print (\"Lyrics:\", raw_dataset[sim_id][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized prod instead of dot product\n",
    "\n",
    "def norm_prod(a,b):\n",
    "    return a*b/( np.sqrt( np.sum(a**2.0) ) * np.sqrt( np.sum(b**2.0) ) )\n",
    "\n",
    "p = norm_prod(lyrics_vector_space[sim_id], lyrics_vector_space[query_id])\n",
    "\n",
    "idx = np.argsort(p)\n",
    "\n",
    "for term_id in np.argsort(idx)[::-1]:\n",
    "    if p[term_id]>0:\n",
    "        print (lexicon_rev_map[term_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do you like it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is this enough ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises:\n",
    "\n",
    " - remove stop-words, too frequent words, unusual/infrequent words\n",
    " - Find the most original song:\n",
    "   - most distant on average?\n",
    "   - most distant from the 10 closest ones?\n",
    " - [advanced] filter using additional functionalities of textblob, e.g., lemmatize rather than stem, use only nouns, anything else comes up to your mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(sorted(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good to know about TextBlob\n",
    "\n",
    "### Get Sentiment/Polarity of first sentence\n",
    "\n",
    "TextBlob provides a polarity score, i.e., a number between -1 (negative) and 1 (positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence(\"I love playing tennis!\").polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence(\"I hate running!\").polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_blob = TextBlob(u\"\")\n",
    "chinese_blob.translate(from_lang=\"zh-CN\", to='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_blob = TextBlob(\"Beauty is better than ugly\")\n",
    "eng_blob.translate(from_lang=\"en\", to='it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    " - **Introduction to Information Retrieval**. Manning, Raghavan, Schtze. Cambridge University Press. 2008.\n",
    "   - Sections 2.1, 2.2, 6.2, 6.3\n",
    "   - Download: https://nlp.stanford.edu/IR-book/information-retrieval-book.html\n",
    " - **Web Data Mining** 2nd edition. Liu. Springer. 2011.\n",
    "   - Sections 6.2.1, 6.2.2, 6.5\n",
    " - **Mining of Massive Datasets**. Leskovec, Rajaraman, Ullman. Cambridge University Press. 2014.\n",
    "   - Sections 3.1\n",
    "   - Download: http://www.mmds.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
